{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaWnlKq8Eq58"
      },
      "source": [
        "## **Retrievers**\n",
        "\n",
        "A Retriever is a component in Langchain that fetches relevant documents from a data source in response to a user's query.\n",
        "\n",
        "There are multiple Retrievers in Langchain:\n",
        "For example: Wikipedia Retriever, Vector Store Retriever, Multi-Query Retriever, and many more.\n",
        "\n",
        "All Retrievers in Langchain are Runnables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-lCtrD4GKqh"
      },
      "source": [
        "# ***1. Wikipedia Retriever:***\n",
        "\n",
        "A Wikipedia Retriever is a retriever that queries a Wikipedia API to fetch relevant content for a given query.\n",
        "\n",
        "**Working--**\n",
        "\n",
        "--> Give a query (ex: \"What is Gen AI\")\n",
        "\n",
        "--> It sends the query to Wikipedia API\n",
        "\n",
        "--> It then retrievers the most relevant articles.\n",
        "\n",
        "--> And then returns them as a Langchain Document Object as response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPp7DHiGHk5k",
        "outputId": "d12aa9b8-025c-47a3-b460-3b354c4d6fc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (4.13.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wikipedia) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.8.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->wikipedia) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhiak84SGaY3",
        "outputId": "2fcccc0d-ba2f-4b56-eb01-ffd3165dab5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.3.31)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=0.3.78 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.78)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.43)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.31)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.11.9)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (1.33)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=0.3.78->langchain_community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=0.3.78->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rT9byHYREYKS"
      },
      "outputs": [],
      "source": [
        "from langchain_community.retrievers import WikipediaRetriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "CvKehD68HNPB"
      },
      "outputs": [],
      "source": [
        "# Initilalize the Retriever\n",
        "wikipedia_retriever = WikipediaRetriever(top_k_results=2,lang=\"en\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hugQbGX9Hd8d"
      },
      "outputs": [],
      "source": [
        "query = \"What is the future of AI in Healthcare ?\"\n",
        "\n",
        "docs = wikipedia_retriever.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iC09kOpfH0iS",
        "outputId": "2fc7532d-0089-4974-f2d7-4536b244b65c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'title': 'Artificial intelligence in healthcare', 'summary': 'Artificial intelligence in healthcare is the application of artificial intelligence (AI) to analyze and understand complex medical and healthcare data. In some cases, it can exceed or augment human capabilities by providing better or faster ways to diagnose, treat, or prevent disease.\\nAs the widespread use of artificial intelligence in healthcare is still relatively new, research is ongoing into its applications across various medical subdisciplines and related industries. AI programs are being applied to practices such as diagnostics, treatment protocol development, drug development, personalized medicine, and patient monitoring and care. Since radiographs are the most commonly performed imaging tests in radiology, the potential for AI to assist with triage and interpretation of radiographs is particularly significant.\\nUsing AI in healthcare presents unprecedented ethical concerns related to issues such as data privacy, automation of jobs, and amplifying already existing algorithmic bias. New technologies such as AI are often met with resistance by healthcare leaders, leading to slow and erratic adoption. There have been cases where AI has been put to use in healthcare without proper testing. A systematic review and thematic analysis in 2023 showed that most stakeholders including health professionals, patients, and the general public doubted that care involving AI could be empathetic. Meta-studies have found that the scientific literature on AI in healthcare often suffers from a lack of reproducibility.\\n\\n', 'source': 'https://en.wikipedia.org/wiki/Artificial_intelligence_in_healthcare'}, page_content=\"Artificial intelligence in healthcare is the application of artificial intelligence (AI) to analyze and understand complex medical and healthcare data. In some cases, it can exceed or augment human capabilities by providing better or faster ways to diagnose, treat, or prevent disease.\\nAs the widespread use of artificial intelligence in healthcare is still relatively new, research is ongoing into its applications across various medical subdisciplines and related industries. AI programs are being applied to practices such as diagnostics, treatment protocol development, drug development, personalized medicine, and patient monitoring and care. Since radiographs are the most commonly performed imaging tests in radiology, the potential for AI to assist with triage and interpretation of radiographs is particularly significant.\\nUsing AI in healthcare presents unprecedented ethical concerns related to issues such as data privacy, automation of jobs, and amplifying already existing algorithmic bias. New technologies such as AI are often met with resistance by healthcare leaders, leading to slow and erratic adoption. There have been cases where AI has been put to use in healthcare without proper testing. A systematic review and thematic analysis in 2023 showed that most stakeholders including health professionals, patients, and the general public doubted that care involving AI could be empathetic. Meta-studies have found that the scientific literature on AI in healthcare often suffers from a lack of reproducibility.\\n\\n\\n== Applications in healthcare systems ==\\n\\n\\n=== Disease diagnosis ===\\nAccurate and early diagnosis of diseases is still a challenge in healthcare. Recognizing medical conditions and their symptoms is a complex problem. AI can assist clinicians with its data processing capabilities to save time and improve accuracy. Through the use of machine learning, artificial intelligence can be able to substantially aid doctors in patient diagnosis through the analysis of mass electronic health records (EHRs). AI can help early prediction, for example, of Alzheimer's disease and dementias, by looking through large numbers of similar cases and possible treatments.\\nDoctors' decision making could also be supported by AI in urgent situations, for example in the emergency department. Here AI algorithms can help prioritize more serious cases and reduce waiting time. Decision support systems augmented with AI can offer real-time suggestions and faster data interpretation to aid the decisions made by healthcare professionals.\\nIn 2023 a study reported higher satisfaction rates with ChatGPT-generated responses compared with those from physicians for medical questions posted on Reddit's r/AskDocs. Evaluators preferred ChatGPT's responses to physician responses in 78.6% of 585 evaluations, noting better quality and empathy. The authors noted that these were isolated questions taken from an online forum, not in the context of an established patient-physician relationship. Moreover, responses were not graded on the accuracy of medical information, and some have argued that the experiment was not properly blinded, with the evaluators being coauthors of the study.\\nRecent developments in statistical physics, machine learning, and inference algorithms are also being explored for their potential in improving medical diagnostic approaches. Also, the establishment of large healthcare-related data warehouses of sometimes hundreds of millions of patients provides extensive training data for AI models.\\n\\n\\n=== Electronic health records ===\\nElectronic health records (EHR) are crucial to the digitalization and information spread of the healthcare industry. Now that around 80% of medical practices use EHR, some anticipate the use of artificial intelligence to interpret the records and provide new information to physicians.\\nOne application uses natural language processing (NLP) to make more succinct reports that limit the variation between medical terms by matching s\"),\n",
              " Document(metadata={'title': 'Artificial general intelligence', 'summary': 'Artificial general intelligence (AGI)—sometimes called human‑level intelligence AI—is a type of artificial intelligence that would match or surpass human capabilities across virtually all cognitive tasks.\\nSome researchers argue that state‑of‑the‑art large language models (LLMs) already exhibit signs of AGI‑level capability, while others maintain that genuine AGI has not yet been achieved. Beyond AGI, artificial superintelligence (ASI) would outperform the best human abilities across every domain by a wide margin.\\nUnlike artificial narrow intelligence (ANI), whose competence is confined to well‑defined tasks, an AGI system can generalise knowledge, transfer skills between domains, and solve novel problems without task‑specific reprogramming. The concept does not, in principle, require the system to be an autonomous agent; a static model—such as a highly capable large language model—or an embodied robot could both satisfy the definition so long as human‑level breadth and proficiency are achieved.\\nCreating AGI is a primary goal of AI research and of companies such as OpenAI, Google, xAI, and Meta. A 2020 survey identified 72 active AGI research and development projects across 37 countries.\\nThe timeline for achieving human‑level intelligence AI remains deeply contested. Recent surveys of AI researchers give median forecasts ranging from the late 2020s to mid‑century, while still recording significant numbers who expect arrival much sooner—or never at all. There is debate on the exact definition of AGI and regarding whether modern LLMs such as GPT-4 are early forms of emerging AGI. AGI is a common topic in science fiction and futures studies.\\nContention exists over whether AGI represents an existential risk. Many AI experts have stated that mitigating the risk of human extinction posed by AGI should be a global priority. Others find the development of AGI to be in too remote a stage to present such a risk.', 'source': 'https://en.wikipedia.org/wiki/Artificial_general_intelligence'}, page_content='Artificial general intelligence (AGI)—sometimes called human‑level intelligence AI—is a type of artificial intelligence that would match or surpass human capabilities across virtually all cognitive tasks.\\nSome researchers argue that state‑of‑the‑art large language models (LLMs) already exhibit signs of AGI‑level capability, while others maintain that genuine AGI has not yet been achieved. Beyond AGI, artificial superintelligence (ASI) would outperform the best human abilities across every domain by a wide margin.\\nUnlike artificial narrow intelligence (ANI), whose competence is confined to well‑defined tasks, an AGI system can generalise knowledge, transfer skills between domains, and solve novel problems without task‑specific reprogramming. The concept does not, in principle, require the system to be an autonomous agent; a static model—such as a highly capable large language model—or an embodied robot could both satisfy the definition so long as human‑level breadth and proficiency are achieved.\\nCreating AGI is a primary goal of AI research and of companies such as OpenAI, Google, xAI, and Meta. A 2020 survey identified 72 active AGI research and development projects across 37 countries.\\nThe timeline for achieving human‑level intelligence AI remains deeply contested. Recent surveys of AI researchers give median forecasts ranging from the late 2020s to mid‑century, while still recording significant numbers who expect arrival much sooner—or never at all. There is debate on the exact definition of AGI and regarding whether modern LLMs such as GPT-4 are early forms of emerging AGI. AGI is a common topic in science fiction and futures studies.\\nContention exists over whether AGI represents an existential risk. Many AI experts have stated that mitigating the risk of human extinction posed by AGI should be a global priority. Others find the development of AGI to be in too remote a stage to present such a risk.\\n\\n\\n== Terminology ==\\nAGI is also known as strong AI, full AI, human-level AI, human-level intelligent AI, or general intelligent action.\\nSome academic sources reserve the term \"strong AI\" for computer programs that will experience sentience or consciousness. In contrast, weak AI (or narrow AI) is able to solve one specific problem but lacks general cognitive abilities. Some academic sources use \"weak AI\" to refer more broadly to any programs that neither experience consciousness nor have a mind in the same sense as humans.\\nRelated concepts include artificial superintelligence and transformative AI. An artificial superintelligence (ASI) is a hypothetical type of AGI that is much more generally intelligent than humans, while the notion of transformative AI relates to AI having a large impact on society, for example, similar to the agricultural or industrial revolution.\\nA framework for classifying AGI by performance and autonomy was proposed in 2023 by Google DeepMind researchers. They define five performance levels of AGI: emerging, competent, expert, virtuoso, and superhuman. For example, a competent AGI is defined as an AI that outperforms 50% of skilled adults in a wide range of non-physical tasks, and a superhuman AGI (i.e. an artificial superintelligence) is similarly defined but with a threshold of 100%. They consider large language models like ChatGPT or LLaMA 2 to be instances of emerging AGI (comparable to unskilled humans). Regarding the autonomy of AGI and associated risks, they define five levels: tool (fully in human control), consultant, collaborator, expert, and agent (fully autonomous).\\n\\n\\n== Characteristics ==\\n\\nVarious popular definitions of intelligence have been proposed. One of the leading proposals is the Turing test. However, there are other well-known definitions, and some researchers disagree with the more popular approaches.\\n\\n\\n=== Intelligence traits ===\\nResearchers generally hold that a system is required to do all of the following to be regarded as an AGI:\\n\\nreason, use strategy, solve puzzles, and make judg')]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZHxsdt0H7U4",
        "outputId": "fbc27f87-6907-4e7b-b563-2e5d07d5c29b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "++++++++++++++++++++++++Document 1++++++++++++++++++++++++++++\n",
            "Artificial intelligence in healthcare is the application of artificial intelligence (AI) to analyze and understand complex medical and healthcare data. In some cases, it can exceed or augment human capabilities by providing better or faster ways to diagnose, treat, or prevent disease.\n",
            "As the widespread use of artificial intelligence in healthcare is still relatively new, research is ongoing into its applications across various medical subdisciplines and related industries. AI programs are being applied to practices such as diagnostics, treatment protocol development, drug development, personalized medicine, and patient monitoring and care. Since radiographs are the most commonly performed imaging tests in radiology, the potential for AI to assist with triage and interpretation of radiographs is particularly significant.\n",
            "Using AI in healthcare presents unprecedented ethical concerns related to issues such as data privacy, automation of jobs, and amplifying already existing algorithmic bias. New technologies such as AI are often met with resistance by healthcare leaders, leading to slow and erratic adoption. There have been cases where AI has been put to use in healthcare without proper testing. A systematic review and thematic analysis in 2023 showed that most stakeholders including health professionals, patients, and the general public doubted that care involving AI could be empathetic. Meta-studies have found that the scientific literature on AI in healthcare often suffers from a lack of reproducibility.\n",
            "\n",
            "\n",
            "== Applications in healthcare systems ==\n",
            "\n",
            "\n",
            "=== Disease diagnosis ===\n",
            "Accurate and early diagnosis of diseases is still a challenge in healthcare. Recognizing medical conditions and their symptoms is a complex problem. AI can assist clinicians with its data processing capabilities to save time and improve accuracy. Through the use of machine learning, artificial intelligence can be able to substantially aid doctors in patient diagnosis through the analysis of mass electronic health records (EHRs). AI can help early prediction, for example, of Alzheimer's disease and dementias, by looking through large numbers of similar cases and possible treatments.\n",
            "Doctors' decision making could also be supported by AI in urgent situations, for example in the emergency department. Here AI algorithms can help prioritize more serious cases and reduce waiting time. Decision support systems augmented with AI can offer real-time suggestions and faster data interpretation to aid the decisions made by healthcare professionals.\n",
            "In 2023 a study reported higher satisfaction rates with ChatGPT-generated responses compared with those from physicians for medical questions posted on Reddit's r/AskDocs. Evaluators preferred ChatGPT's responses to physician responses in 78.6% of 585 evaluations, noting better quality and empathy. The authors noted that these were isolated questions taken from an online forum, not in the context of an established patient-physician relationship. Moreover, responses were not graded on the accuracy of medical information, and some have argued that the experiment was not properly blinded, with the evaluators being coauthors of the study.\n",
            "Recent developments in statistical physics, machine learning, and inference algorithms are also being explored for their potential in improving medical diagnostic approaches. Also, the establishment of large healthcare-related data warehouses of sometimes hundreds of millions of patients provides extensive training data for AI models.\n",
            "\n",
            "\n",
            "=== Electronic health records ===\n",
            "Electronic health records (EHR) are crucial to the digitalization and information spread of the healthcare industry. Now that around 80% of medical practices use EHR, some anticipate the use of artificial intelligence to interpret the records and provide new information to physicians.\n",
            "One application uses natural language processing (NLP) to make more succinct reports that limit the variation between medical terms by matching s\n",
            "\n",
            "++++++++++++++++++++++++Document 2++++++++++++++++++++++++++++\n",
            "Artificial general intelligence (AGI)—sometimes called human‑level intelligence AI—is a type of artificial intelligence that would match or surpass human capabilities across virtually all cognitive tasks.\n",
            "Some researchers argue that state‑of‑the‑art large language models (LLMs) already exhibit signs of AGI‑level capability, while others maintain that genuine AGI has not yet been achieved. Beyond AGI, artificial superintelligence (ASI) would outperform the best human abilities across every domain by a wide margin.\n",
            "Unlike artificial narrow intelligence (ANI), whose competence is confined to well‑defined tasks, an AGI system can generalise knowledge, transfer skills between domains, and solve novel problems without task‑specific reprogramming. The concept does not, in principle, require the system to be an autonomous agent; a static model—such as a highly capable large language model—or an embodied robot could both satisfy the definition so long as human‑level breadth and proficiency are achieved.\n",
            "Creating AGI is a primary goal of AI research and of companies such as OpenAI, Google, xAI, and Meta. A 2020 survey identified 72 active AGI research and development projects across 37 countries.\n",
            "The timeline for achieving human‑level intelligence AI remains deeply contested. Recent surveys of AI researchers give median forecasts ranging from the late 2020s to mid‑century, while still recording significant numbers who expect arrival much sooner—or never at all. There is debate on the exact definition of AGI and regarding whether modern LLMs such as GPT-4 are early forms of emerging AGI. AGI is a common topic in science fiction and futures studies.\n",
            "Contention exists over whether AGI represents an existential risk. Many AI experts have stated that mitigating the risk of human extinction posed by AGI should be a global priority. Others find the development of AGI to be in too remote a stage to present such a risk.\n",
            "\n",
            "\n",
            "== Terminology ==\n",
            "AGI is also known as strong AI, full AI, human-level AI, human-level intelligent AI, or general intelligent action.\n",
            "Some academic sources reserve the term \"strong AI\" for computer programs that will experience sentience or consciousness. In contrast, weak AI (or narrow AI) is able to solve one specific problem but lacks general cognitive abilities. Some academic sources use \"weak AI\" to refer more broadly to any programs that neither experience consciousness nor have a mind in the same sense as humans.\n",
            "Related concepts include artificial superintelligence and transformative AI. An artificial superintelligence (ASI) is a hypothetical type of AGI that is much more generally intelligent than humans, while the notion of transformative AI relates to AI having a large impact on society, for example, similar to the agricultural or industrial revolution.\n",
            "A framework for classifying AGI by performance and autonomy was proposed in 2023 by Google DeepMind researchers. They define five performance levels of AGI: emerging, competent, expert, virtuoso, and superhuman. For example, a competent AGI is defined as an AI that outperforms 50% of skilled adults in a wide range of non-physical tasks, and a superhuman AGI (i.e. an artificial superintelligence) is similarly defined but with a threshold of 100%. They consider large language models like ChatGPT or LLaMA 2 to be instances of emerging AGI (comparable to unskilled humans). Regarding the autonomy of AGI and associated risks, they define five levels: tool (fully in human control), consultant, collaborator, expert, and agent (fully autonomous).\n",
            "\n",
            "\n",
            "== Characteristics ==\n",
            "\n",
            "Various popular definitions of intelligence have been proposed. One of the leading proposals is the Turing test. However, there are other well-known definitions, and some researchers disagree with the more popular approaches.\n",
            "\n",
            "\n",
            "=== Intelligence traits ===\n",
            "Researchers generally hold that a system is required to do all of the following to be regarded as an AGI:\n",
            "\n",
            "reason, use strategy, solve puzzles, and make judg\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print documents in clean format\n",
        "\n",
        "for i,doc in enumerate(docs):\n",
        "  print(f\"++++++++++++++++++++++++Document {i+1}++++++++++++++++++++++++++++\")\n",
        "  print(doc.page_content)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SduUxOs_IuAh"
      },
      "source": [
        "# ***2. Vector Store Retriever:***\n",
        "\n",
        "A Vector Store Retriever lets you search and fetch documents from a vector store based on semantic similarity using vector embeddings.\n",
        "\n",
        "**Working--**\n",
        "\n",
        "--> Store Documents in a vector store (ex: ChromaDB, FAISS, Pinecone,etc.)\n",
        "\n",
        "--> Each document is converted into a dense vector using embedding model.\n",
        "\n",
        "--> When a user enters a query:\n",
        "\n",
        "----> It is also turned into a vector\n",
        "\n",
        "----> The retrievers compares the query vector with the stored vectors.\n",
        "\n",
        "----> It retrievers the top k most relevant one documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "id": "Cg3L0k30KKKk",
        "outputId": "3db288b6-070b-4102-b4b8-a91c567f7900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.12/dist-packages (2.1.12)\n",
            "Requirement already satisfied: langchain-core>=0.3.75 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (0.3.78)\n",
            "Collecting google-ai-generativelanguage<1,>=0.7 (from langchain_google_genai)\n",
            "  Using cached google_ai_generativelanguage-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (2.11.9)\n",
            "Requirement already satisfied: filetype<2,>=1.2 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (0.4.31)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (4.15.0)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.3.75->langchain_google_genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.32.5)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.3.75->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (0.25.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<1,>=0.7->langchain_google_genai) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.3.75->langchain_google_genai) (1.3.1)\n",
            "Using cached google_ai_generativelanguage-0.7.0-py3-none-any.whl (1.4 MB)\n",
            "Installing collected packages: google-ai-generativelanguage\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-ai-generativelanguage-0.7.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "ddce9ec2e0f2496686b1292914a8a85c",
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KiyzAvByIF20"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.vectorstores import Chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "0d7haffcLSLC"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document\n",
        "\n",
        "doc1 = Document(\n",
        "        page_content=(\"Virat Kohli is one of the most consistent batsmen in IPL history. He has led the Royal Challengers Bengaluru with passion and intensity.\"),\n",
        "        metadata={\"team\": \"Royal Challengers Bengaluru\"}\n",
        "      )\n",
        "\n",
        "doc2 = Document(\n",
        "        page_content=(\"MS Dhoni is a legendary finisher and one of the best captains in IPL.He has guided Chennai Super Kings to multiple IPL titles.\"),\n",
        "        metadata={\"team\": \"Chennai Super Kings\"}\n",
        "      )\n",
        "\n",
        "doc3 = Document(\n",
        "        page_content=(\"Ravindra Jadeja is a dynamic all-rounder known for his sharp fielding. He plays a crucial role for Chennai Super Kings in both batting and bowling.\"),\n",
        "        metadata={\"team\": \"Chennai Super Kings\"}\n",
        "      )\n",
        "\n",
        "doc4 = Document(\n",
        "        page_content=(\"Jasprit Bumrah is one of the most lethal fast bowlers in IPL. He has been a key match-winner for Mumbai Indians with his death bowling.\"),\n",
        "        metadata={\"team\": \"Mumbai Indians\"}\n",
        "      )\n",
        "\n",
        "doc5 = Document(\n",
        "        page_content=(\"Rohit Sharma is known for his calm leadership and explosive batting. He has captained Mumbai Indians to multiple championship victories.\"),\n",
        "        metadata={\"team\": \"Mumbai Indians\"}\n",
        "     )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "C58CGVAYLrPY"
      },
      "outputs": [],
      "source": [
        "docss = [doc1,doc2,doc3,doc4,doc5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EKUGKvKKVP5",
        "outputId": "5e02c1ba-11a9-489c-a19a-b1b1fa79a455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.9)\n",
            "Requirement already satisfied: pybase64>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.37.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.23.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.0.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.19.2)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (34.1.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (5.2.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.5)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: urllib3<2.4.0,>=1.24.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.35.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Requirement already satisfied: uvloop>=0.15.1 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.10)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CshZGJaOLtYH",
        "outputId": "0e294592-1f56-476f-d968-c464061205c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3092817540.py:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  vector_store = Chroma(\n"
          ]
        }
      ],
      "source": [
        "GOOGLE_API_KEY = \"\"\n",
        "\n",
        "embedding_function = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\",google_api_key=GOOGLE_API_KEY)\n",
        "\n",
        "vector_store = Chroma(\n",
        "    embedding_function=embedding_function,\n",
        "    persist_directory=\"Chroma_DB_Retriever\",\n",
        "    collection_name=\"My_Collection\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sygLGTJLy3I",
        "outputId": "4c235103-7f8d-45dc-8c1a-3afb51179383"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['25ed9c56-95ca-4350-a7d4-1dea776c6a21',\n",
              " '80fddcf1-51fe-47f2-9a96-a48027e4cb12',\n",
              " '8dc97eb6-6777-4537-86ff-1210da5c8e1a',\n",
              " '64ae3398-7911-465a-affd-20010018d5f4',\n",
              " '17b5db7a-8d80-4604-8b2c-badb40b94908']"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add documents in Chroma DB\n",
        "vector_store.add_documents(docss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "6zXaierNMKX6"
      },
      "outputs": [],
      "source": [
        "vector_store_retriever = vector_store.as_retriever(search_kwargs={\"k\":2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "L8OSO3O6McET"
      },
      "outputs": [],
      "source": [
        "query = \"Who is the captain of Chennai Super Kings IPL Team?\"\n",
        "docss = vector_store_retriever.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VM7gwDTMMlMR",
        "outputId": "d74eaaab-8f19-4d10-8061-46f09286af21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'team': 'Chennai Super Kings'}, page_content='MS Dhoni is a legendary finisher and one of the best captains in IPL.He has guided Chennai Super Kings to multiple IPL titles.'),\n",
              " Document(metadata={'team': 'Chennai Super Kings'}, page_content='MS Dhoni is a legendary finisher and one of the best captains in IPL.He has guided Chennai Super Kings to multiple IPL titles.')]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PCGWAA0MlxS",
        "outputId": "945ef5bf-4e7c-4526-8bd5-308b06872e8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "++++++++++++++++++++++++Document 1++++++++++++++++++++++++++++\n",
            "MS Dhoni is a legendary finisher and one of the best captains in IPL.He has guided Chennai Super Kings to multiple IPL titles.\n",
            "\n",
            "++++++++++++++++++++++++Document 2++++++++++++++++++++++++++++\n",
            "MS Dhoni is a legendary finisher and one of the best captains in IPL.He has guided Chennai Super Kings to multiple IPL titles.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i,doc1 in enumerate(docss):\n",
        "  print(f\"++++++++++++++++++++++++Document {i+1}++++++++++++++++++++++++++++\")\n",
        "  print(doc1.page_content)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Huh7mV_RPwe"
      },
      "source": [
        "## ***3. Maximal Marginal Relevance (MMR)***\n",
        "\n",
        "*“How can we pick results that are not only relevant to the query but also different from each other?”*\n",
        "\n",
        "MMR is an information retrieval algorithm designed to reduce redundancy in the retrieved results while maintaining high relevance to the query.\n",
        "\n",
        "**🤔 Why MMR Retriever?**\n",
        "\n",
        "**In regular similarity search, you may get documents that are:**\n",
        "\n",
        "-> All very similar to each other\n",
        "\n",
        "-> Repeating the same info\n",
        "\n",
        "-> Lacking diverse perspectives\n",
        "\n",
        "**MMR Retriever avoids that by:**\n",
        "\n",
        "-> Picking the most relevant document first\n",
        "\n",
        "-> Then picking the next most relevant and least similar to already selected docs\n",
        "\n",
        "-> And so on…\n",
        "\n",
        "**This helps especially in RAG pipelines where:**\n",
        "\n",
        "--> You want your context window to contain diverse but still relevant information\n",
        "\n",
        "--> Avoiding redundancy due to semantically overlapping documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBEPuKhzSIwj"
      },
      "source": [
        "### **Example: Maximal Marginal Relevance (MMR) Retriever**\n",
        "\n",
        "The goal is to pick results that are both relevant to the query and diverse (not repeating similar info).\n",
        "\n",
        "Suppose we have 5 documents (D1–D5) about climate change.\n",
        "\n",
        "**Doc ID\tContent**\n",
        "\n",
        "D1 ==\t“Climate change is causing glaciers to melt rapidly in the Arctic region.”\n",
        "\n",
        "D2 ==\t“Glaciers in the Arctic are melting at an alarming rate due to rising temperatures.”\n",
        "\n",
        "D3 == “Deforestation in the Amazon is accelerating global climate change.”\n",
        "\n",
        "D4 == “Climate change is increasing the frequency of wildfires in California.”\n",
        "\n",
        "D5 ==\t“Rising sea levels due to climate change threaten coastal cities like Mumbai and New York.”\n",
        "\n",
        "***Normal Similarity Search (no MMR):***\n",
        "\n",
        "Top 3 results:\n",
        "\n",
        "D1 – Arctic glaciers melting\n",
        "\n",
        "D2 – Arctic glaciers melting\n",
        "\n",
        "D3 – Deforestation in Amazon\n",
        "\n",
        "👉 Problem: D1 and D2 are too similar (redundant).\n",
        "\n",
        "***MMR Retriever:***\n",
        "\n",
        "Top 3 results:\n",
        "\n",
        "D1 – Arctic glaciers melting\n",
        "\n",
        "D4 – Wildfires in California\n",
        "\n",
        "D5 – Rising sea levels in coastal cities\n",
        "\n",
        "👉 Benefit: All are relevant to climate change but cover different aspects — glaciers, wildfires, and sea levels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "F-HyzU_wM8u8"
      },
      "outputs": [],
      "source": [
        "d1 = Document(page_content = \"Climate change is causing glaciers to melt rapidly in the Arctic region.\")\n",
        "d2 = Document(page_content = \"Glaciers in the Arctic are melting at an alarming rate due to rising temperatures.\")\n",
        "d3 = Document(page_content = \"Deforestation in the Amazon is accelerating global climate change.\")\n",
        "d4 = Document(page_content = \"Climate change is increasing the frequency of wildfires in California.\")\n",
        "d5 = Document(page_content = \"Rising sea levels due to climate change threaten coastal cities like Mumbai and New York.\")\n",
        "\n",
        "all_docs = [d1, d2, d3, d4, d5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0l2dK6cTPpI"
      },
      "outputs": [],
      "source": [
        "GOOGLE_API_KEY = \"\"\n",
        "\n",
        "embedding_function = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\",google_api_key=GOOGLE_API_KEY)\n",
        "\n",
        "vector_store = Chroma(\n",
        "    embedding_function=embedding_function,\n",
        "    persist_directory=\"Chroma_DB_Retriever_MMR\",\n",
        "    collection_name=\"My_Collection\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-3LJkudTV3V",
        "outputId": "64f06f97-f23c-45c0-a920-f2adc8c901b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ac1872a1-c4b2-4630-8c3a-260ce060701b',\n",
              " 'f428b339-1856-4b73-bc76-230d7ae60920',\n",
              " '3be2c901-e188-4cca-9812-132d29ce2b8f',\n",
              " '5fd7c486-fbf7-497a-9a33-fea456cae068',\n",
              " '1ee016c4-47b2-4bbf-bf30-5953bce62a15']"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add documents in Chroma DB\n",
        "vector_store.add_documents(all_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "77KVAIYoTZhi"
      },
      "outputs": [],
      "source": [
        "# using normal vanilla retriever\n",
        "\n",
        "vector_store_retriever = vector_store.as_retriever(search_kwargs={\"k\":3})\n",
        "query = \"What is the effect of glaciers melting on climate change ?\"\n",
        "docss1 = vector_store_retriever.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzeQxTgST8jc",
        "outputId": "6d702e12-745b-4a0a-93de-39cba2ea2407"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='Climate change is causing glaciers to melt rapidly in the Arctic region.'),\n",
              " Document(metadata={}, page_content='Climate change is causing glaciers to melt rapidly in the Arctic region.'),\n",
              " Document(metadata={}, page_content='Glaciers in the Arctic are melting at an alarming rate due to rising temperatures.')]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docss1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "NqmBqorgT9px"
      },
      "outputs": [],
      "source": [
        "# using mmr retriever\n",
        "\n",
        "vector_store_retriever_mmr = vector_store.as_retriever(search_type=\"mmr\",search_kwargs={\"k\":3})\n",
        "query = \"What is the effect of glaciers melting on climate change ?\"\n",
        "docss2 = vector_store_retriever_mmr.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGy7tsd8UiwX",
        "outputId": "a4d6671a-217f-412b-f247-eb2d451380c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='Climate change is causing glaciers to melt rapidly in the Arctic region.'),\n",
              " Document(metadata={}, page_content='Deforestation in the Amazon is accelerating global climate change.'),\n",
              " Document(metadata={}, page_content='Climate change is increasing the frequency of wildfires in California.')]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docss2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z64IBSaKoNt"
      },
      "source": [
        "## ***4. Multi-Query Retriever***\n",
        "\n",
        "*\"Sometimes a single query cannot capture all the ways of informantion phrased in your documents.\"*\n",
        "\n",
        "Query: \"How can I say healthy ?\"\n",
        "\n",
        "Could **Mean**:\n",
        "\n",
        "--> What food should I eat ?\n",
        "\n",
        "--> How often should I exercise ?\n",
        "\n",
        "--> How can I manage stress ?\n",
        "\n",
        "A simple similarity search might miss documents that talk about those things but dont use the word 'healthy'.\n",
        "\n",
        "**Working:**\n",
        "\n",
        "--> Take your original query\n",
        "\n",
        "--> Use LLM (ex: OpenAI, Gemini) to generate multiple syemantically different versions of that query.\n",
        "\n",
        "--> Performs retriever for each sub-query.\n",
        "\n",
        "--> Combines and deduplicate the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-NxX2kwOjyF",
        "outputId": "bd2fd367-4c66-43d5-d435-feb050af3c57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Kt7zidaOUjsk"
      },
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "NJ_NXr19M47G"
      },
      "outputs": [],
      "source": [
        "# Relevant health & wellness documents\n",
        "all_docs1 = [\n",
        "    Document (page_content=\"Regular walking boosts heart health and can reduce symptoms of depression.\", metadata={\"source\": \"H1\"}),\n",
        "    Document (page_content=\"Consuming leafy greens and fruits helps detox the body and improve longevity.\", metadata={\"source\": \"H2\"}),\n",
        "    Document (page_content=\"Deep sleep is crucial for cellular repair and emotional regulation.\", metadata={\"source\": \"H3\"}),\n",
        "    Document (page_content=\"Mindfulness and controlled breathing lower cortisol and improve mental clarity.\", metadata={\"source\": \"H4\"}),\n",
        "    Document (page_content=\"Drinking sufficient water throughout the day helps maintain metabolism and energy.\", metadata={\"source\": \"H5\"}),\n",
        "    Document (page_content=\"The solar energy system in modern homes helps balance electricity demand.\", metadata={\"source\": \"I1\"}),\n",
        "    Document (page_content=\"Python balances readability with power, making it a popular system design language\", metadata={\"source\": \"I2\"}),\n",
        "    Document (page_content=\"Photosynthesis enables plants to produce energy by converting sunlight.\", metadata={\"source\": \"I3\"}),\n",
        "    Document (page_content=\"The 2022 FIFA World Cup was held in Qatar and drew global energy and excitement.\", metadata={\"source\": \"I4\"}),\n",
        "    Document (page_content=\"Black holes bend spacetime and store immense gravitational energy.\", metadata={\"source\": \"I5\"})\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfGjOY7_NhDJ"
      },
      "outputs": [],
      "source": [
        "GOOGLE_API_KEY = \"\"\n",
        "\n",
        "embedding_function = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\",google_api_key=GOOGLE_API_KEY)\n",
        "\n",
        "vector_store = Chroma(\n",
        "    embedding_function=embedding_function,\n",
        "    persist_directory=\"Chroma_DB_Retriever_Multi_Query\",\n",
        "    collection_name=\"My_Collection\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omtuMwJucVXL",
        "outputId": "a841aa55-b238-47ee-ae47-e1cc43ec8c7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['d0581231-ce8b-4040-a2b7-a4bb27ebfac4',\n",
              " 'b0162943-b280-4723-8d7b-fe1f97fee457',\n",
              " 'fb852b31-fe9a-4c45-a8e4-d62773762c75',\n",
              " '0ffaf966-aad4-418e-bdf7-27a284a03e0b',\n",
              " '6825916e-ae7b-4454-bbdd-7a065df9a9e1',\n",
              " '138a3edf-7552-470c-a7dc-3cf1e262da99',\n",
              " 'ff5bc3dd-7262-4639-9ee3-f050471b48b4',\n",
              " 'e3f17a87-368a-4163-be92-3f5d76828c69',\n",
              " '03a32e54-4ea6-40da-ac67-12648b6c0b18',\n",
              " 'bdd8dd64-623e-43b5-8dcd-309961ae2cfd']"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_store.add_documents(all_docs1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "kb4MKWZMa7M3"
      },
      "outputs": [],
      "source": [
        "query = \"How to improve energy levels and maintain balance ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "FUFfq7iwP8AF"
      },
      "outputs": [],
      "source": [
        "# # Create a simple similarity retriever\n",
        "\n",
        "vector_store_retriever = vector_store.similarity_search(query,k=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1LrvK5_QRCo",
        "outputId": "d6275f96-ab2a-439f-adf0-335150801653"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " SIMPLE SIMILARITY RETRIEVER RESULTS \n",
            " \n",
            "++++++++++++++++++++++++Document 1++++++++++++++++++++++++++++\n",
            "Drinking sufficient water throughout the day helps maintain metabolism and energy.\n",
            "\n",
            "++++++++++++++++++++++++Document 2++++++++++++++++++++++++++++\n",
            "Mindfulness and controlled breathing lower cortisol and improve mental clarity.\n",
            "\n",
            "++++++++++++++++++++++++Document 3++++++++++++++++++++++++++++\n",
            "Consuming leafy greens and fruits helps detox the body and improve longevity.\n",
            "\n",
            "++++++++++++++++++++++++Document 4++++++++++++++++++++++++++++\n",
            "The solar energy system in modern homes helps balance electricity demand.\n",
            "\n",
            "++++++++++++++++++++++++Document 5++++++++++++++++++++++++++++\n",
            "Deep sleep is crucial for cellular repair and emotional regulation.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\" SIMPLE SIMILARITY RETRIEVER RESULTS \\n \")\n",
        "for i,d in enumerate(vector_store_retriever):\n",
        "  print(f\"++++++++++++++++++++++++Document {i+1}++++++++++++++++++++++++++++\")\n",
        "  print(d.page_content)\n",
        "  print()\n",
        "\n",
        "# Here the last Document 4 is not at all relevant to Health"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "MYByPvV8SZ3D"
      },
      "outputs": [],
      "source": [
        "# Multi-Query Retriever\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=vector_store.as_retriever(k=5),\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "_FzosRqkdYro"
      },
      "outputs": [],
      "source": [
        "multi_query_retriever_result = multi_query_retriever.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuJzJDQfd4Ln",
        "outputId": "22fe0a84-5925-471c-a90d-86d83ef4bd77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " MULTI QUERY RETRIEVER RESULTS \n",
            " \n",
            "++++++++++++++++++++++++Document 1++++++++++++++++++++++++++++\n",
            "Mindfulness and controlled breathing lower cortisol and improve mental clarity.\n",
            "\n",
            "++++++++++++++++++++++++Document 2++++++++++++++++++++++++++++\n",
            "Drinking sufficient water throughout the day helps maintain metabolism and energy.\n",
            "\n",
            "++++++++++++++++++++++++Document 3++++++++++++++++++++++++++++\n",
            "Deep sleep is crucial for cellular repair and emotional regulation.\n",
            "\n",
            "++++++++++++++++++++++++Document 4++++++++++++++++++++++++++++\n",
            "Regular walking boosts heart health and can reduce symptoms of depression.\n",
            "\n",
            "++++++++++++++++++++++++Document 5++++++++++++++++++++++++++++\n",
            "Consuming leafy greens and fruits helps detox the body and improve longevity.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\" MULTI QUERY RETRIEVER RESULTS \\n \")\n",
        "for i,d in enumerate(multi_query_retriever_result):\n",
        "  print(f\"++++++++++++++++++++++++Document {i+1}++++++++++++++++++++++++++++\")\n",
        "  print(d.page_content)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjfoNxMkfusJ"
      },
      "source": [
        "## ***5. Contextual Compression Retriever***\n",
        "\n",
        "The Contextual Compression Retriever in LangChain is an advanced retriever that improves retrieval quality by compressing documents after retrieval - keeping only the relevant content based on the user's query.\n",
        "\n",
        "**Query: \"What is photosynthesis?\"**\n",
        "\n",
        "Retrieved Document (by a traditional retriever):\n",
        "\n",
        "\"The Grand Canyon is a famous natural site.\n",
        "Photosynthesis is how plants convert light into energy.\n",
        "Many tourists visit every year.\"\n",
        "\n",
        "**Problem:**\n",
        "\n",
        "• The retriever returns the entire paragraph\n",
        "\n",
        "• Only one sentence is actually relevant to the query\n",
        "\n",
        "• The rest is irrelevant noise that wastes context window and may confuse the LLM\n",
        "\n",
        "**What Contextual Compression Retriever does:**\n",
        "\n",
        "Returns only the relevant part, e.g. \"Photosynthesis is how plants convert light into energy.\"\n",
        "\n",
        "**How It Works**\n",
        "\n",
        "1. Base Retriever (e.g., FAISS, Chroma) retrieves N documents.\n",
        "2. A compressor (usually an LLM) is applied to each document.\n",
        "3. The compressor keeps only the parts relevant to the query.\n",
        "4. Irrelevant content is discarded.\n",
        "\n",
        "**When to Use**\n",
        "\n",
        "--> Your documents are long and contain mixed information\n",
        "\n",
        "--> You want to reduce context length for LLMs\n",
        "\n",
        "--> You need to improve answer accuracy in RAG pipelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "QGDA0sTvhFxI"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "wKf33wZdkBl_"
      },
      "outputs": [],
      "source": [
        "all_docs2 = [\n",
        "    Document (page_content=\"Regular walking boosts heart health and can reduce symptoms of depression.\", metadata={\"source\": \"H1\"}),\n",
        "    Document (page_content=\"Consuming leafy greens and fruits helps detox the body and improve longevity. Tesla Autonomous Car is the example of Agentic AI systems.\", metadata={\"source\": \"H2\"}),\n",
        "    Document (page_content=\"Agentic AI is a form of artificial intelligence that can independently set goals, plan complex, multi-step actions, and adapt to dynamic environments to achieve an objective with minimal human supervision. Deep sleep is crucial for cellular repair and emotional regulation.\", metadata={\"source\": \"H3\"}),\n",
        "    Document (page_content=\"Mindfulness and controlled breathing lower cortisol and improve mental clarity.\", metadata={\"source\": \"H4\"}),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW8hl7H2kkGK",
        "outputId": "11674c0d-e33b-4f41-cd9d-2a0a4cc7840b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['21ca0b45-0604-4d28-9a01-c184f67ed07d',\n",
              " '27f4b5fe-1f99-4c30-96c5-f4d1a9171bc7',\n",
              " 'd8634f39-b080-4b7a-a347-bdf4758617bb',\n",
              " '29e4aa59-7b55-42de-a2e1-2c4bd50f6793']"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_store.add_documents(all_docs2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "j1yjNbNdk8M9"
      },
      "outputs": [],
      "source": [
        "query = \"What is Agentic AI ?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddDCdcU3kpPm",
        "outputId": "a1a1f3d8-9571-420d-87b5-a34a3d771fa8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " SIMPLE SIMILARITY RETRIEVER RESULTS \n",
            " \n",
            "++++++++++++++++++++++++Document 1++++++++++++++++++++++++++++\n",
            "Agentic AI is a form of artificial intelligence that can independently set goals, plan complex, multi-step actions, and adapt to dynamic environments to achieve an objective with minimal human supervision. Deep sleep is crucial for cellular repair and emotional regulation.\n",
            "\n",
            "++++++++++++++++++++++++Document 2++++++++++++++++++++++++++++\n",
            "Consuming leafy greens and fruits helps detox the body and improve longevity. Tesla Autonomous Car is the example of Agentic AI systems.\n",
            "\n",
            "++++++++++++++++++++++++Document 3++++++++++++++++++++++++++++\n",
            "Deep sleep is crucial for cellular repair and emotional regulation.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# # Create a simple similarity retriever\n",
        "\n",
        "vector_store_retriever = vector_store.similarity_search(query,k=3)\n",
        "print(\" SIMPLE SIMILARITY RETRIEVER RESULTS \\n \")\n",
        "for i,d in enumerate(vector_store_retriever):\n",
        "  print(f\"++++++++++++++++++++++++Document {i+1}++++++++++++++++++++++++++++\")\n",
        "  print(d.page_content)\n",
        "  print()\n",
        "\n",
        "# Here we got correct documents but many of them are of mixed context\n",
        "# Like we asked about Agentic AI and we are getting results related to health as well as the documents are only like that.\n",
        "# Hence, this is where Contextual Compression Retriever comes into picture, it will trim the rest part of documents and will provide us with only the result that is similar to our query.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "tlYkLfiekysV"
      },
      "outputs": [],
      "source": [
        "# ContextualCompressionRetriever\n",
        "\n",
        "llm2 = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\")\n",
        "compressor = LLMChainExtractor.from_llm(llm2)\n",
        "base_retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})\n",
        "\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=base_retriever\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "Y__5GF8rmIEj"
      },
      "outputs": [],
      "source": [
        "result = compression_retriever.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrNxcvQpmK4t",
        "outputId": "72b9fac2-9969-4f41-eebf-848d9d2a877f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " SIMPLE SIMILARITY RETRIEVER RESULTS \n",
            " \n",
            "++++++++++++++++++++++++Document 1++++++++++++++++++++++++++++\n",
            "Agentic AI is a form of artificial intelligence that can independently set goals, plan complex, multi-step actions, and adapt to dynamic environments to achieve an objective with minimal human supervision.\n",
            "\n",
            "++++++++++++++++++++++++Document 2++++++++++++++++++++++++++++\n",
            "Tesla Autonomous Car is the example of Agentic AI systems.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\" SIMPLE SIMILARITY RETRIEVER RESULTS \\n \")\n",
        "for i,d in enumerate(result):\n",
        "  print(f\"++++++++++++++++++++++++Document {i+1}++++++++++++++++++++++++++++\")\n",
        "  print(d.page_content)\n",
        "  print()\n",
        "\n",
        "# Here now the rest of the content got trim and only content relevant to query is displayed."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
